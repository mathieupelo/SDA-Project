{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "from Utils.Solver import *\n",
    "from Utils.Signals import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assume we are interested in the following stocks: AAPL, MSFT, TSLA, AMZN, GOOG\n",
    "tickers = ['AAPL', 'MSFT', 'TSLA', 'AMZN', 'GOOG', 'IBM', 'NFLX', 'NVDA', 'AMD', 'INTC', 'TXN', 'QCOM', 'MU', 'ADI', 'HPQ', 'GLW', 'AVGO', 'ADP', 'INTU', 'PFE'] \n",
    "\n",
    "# Download historical stock data\n",
    "data = yf.download(tickers, start='2010-01-01', end='2025-01-01')\n",
    "# Initialize the portfolio solver with appropriate penalty and max weight threshold\n",
    "portfolio_solver = Portfolio_Solver(0.8, max_weight_threshold=0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_signal = '2000-01-01'\n",
    "end_date_signal = '2021-01-01'\n",
    "date_range_signal = pd.date_range(start=start_date_signal, end=end_date_signal)\n",
    "\n",
    "start_date_eval = '2019-01-01'\n",
    "end_date_eval = '2020-01-01'\n",
    "date_range_eval = pd.date_range(start=start_date_eval, end=end_date_eval)\n",
    "\n",
    "display(date_range_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 2000-09-04 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-05 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-06 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-07 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-08 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-09 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-10 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-11 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-12 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-13 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-14 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-15 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-16 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-17 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-18 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-19 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-20 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-21 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-22 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-23 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-24 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-25 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-26 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-27 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-28 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-29 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-09-30 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-10-01 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n",
      "processing 2000-10-02 00:00:00 : [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan], [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan] \n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty list to store the rows for the first DataFrame\n",
    "dataset_scores = []\n",
    "\n",
    "# Step 1: Create the DataFrame with rsi_scores, macd_scores, and sma_scores\n",
    "for date in date_range_signal:\n",
    "\n",
    "    # Step 1a: Calculate the RSI signal scores\n",
    "    rsi_signal_scores = calculate_rsi_signal(data, tickers, date=date, period=14)\n",
    "    rsi_scores = np.array([score[1] for score in rsi_signal_scores])\n",
    "\n",
    "    # Step 1b: Calculate the MACD signal scores\n",
    "    macd_signal_scores = calculate_macd_signal(data, tickers, date=date)\n",
    "    macd_scores = np.array([score[1] for score in macd_signal_scores])\n",
    "\n",
    "    # Step 1c: Calculate the SMA signal scores\n",
    "    sma_signal_scores = calculate_sma_signal(data, tickers, date=date)\n",
    "    sma_scores = np.array([score[1] for score in sma_signal_scores])\n",
    "\n",
    "    print(f\"processing {date} : {rsi_scores}, {macd_scores}, {sma_scores} \")\n",
    "\n",
    "    if np.any(np.isnan(rsi_scores)) or np.any(np.isnan(macd_scores)) or np.any(np.isnan(sma_scores)):\n",
    "        #print(f\"Skipping {date} due to NaN values in the signals.\")\n",
    "        continue  # Skip this date and move to the next one\n",
    "\n",
    "    \n",
    "\n",
    "    # Step 1d: Add the scores to the first dataset\n",
    "    dataset_scores.append({\n",
    "        'date': date,\n",
    "        'rsi_scores': rsi_scores,\n",
    "        'macd_scores': macd_scores,\n",
    "        'sma_scores': sma_scores\n",
    "    })\n",
    "\n",
    "\n",
    "# Convert the first dataset into a DataFrame\n",
    "df_scores = pd.DataFrame(dataset_scores)\n",
    "display(df_scores.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date_train = '2018-01-01'\n",
    "end_date_train = '2019-01-01'\n",
    "date_range_train = pd.date_range(start=start_date_train, end=end_date_train)\n",
    "\n",
    "start_date_eval = '2020-01-01'\n",
    "end_date_eval = '2021-01-01'\n",
    "date_range_eval = pd.date_range(start=start_date_eval, end=end_date_eval)\n",
    "\n",
    "# Filter the dataframe within the date range\n",
    "df_train = df_scores[(df_scores['date'] >= start_date_train) & (df_scores['date'] <= end_date_train)]\n",
    "display(df_train)\n",
    "df_eval = df_scores[(df_scores['date'] >= start_date_eval) & (df_scores['date'] <= end_date_eval)]\n",
    "display(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights with small random values or equal weights\n",
    "signal_weights = np.array([1/3, 1/3, 1/3])  # [w_rsi, w_macd, w_sma]\n",
    "\n",
    "\n",
    "avg_annualized_return, total_return_sum = portfolio_solver. calculate_eval_returns(\n",
    "    tickers, data, df_eval, signal_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_annualized_return, total_return_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
